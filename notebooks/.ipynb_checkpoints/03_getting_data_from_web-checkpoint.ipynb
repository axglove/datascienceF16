{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests     # how python goes onto the internet!\n",
    "import re           # regex\n",
    "from bs4 import BeautifulSoup # a python HTML parser (version 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's turn to stock prices\n",
    "# http://finance.google.com/finance?q=aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol = 'aapl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's grab the raw html from the page\n",
    "r = requests.get('http://finance.google.com/finance?q='+symbol) # the url of the google finance page goes in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = BeautifulSoup(r.text, \"html5lib\") # create a beautifulsoup object\n",
    "# b = BeautifulSoup(r.text, 'html.parser') # try this line instead if you have problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.prettify() # will print the html nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find all span tags\n",
    "b.findAll('span')\n",
    "# b.find_all('span') for bs4 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the pattern we recognized from the website\n",
    "re_tag = re.compile(\"ref_\\d+_l\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this tag finds the tag with the price in it!!!!\n",
    "span_tag = b.find('span', attrs={'id': re_tag}) \n",
    "# use find to return THE ONE AND ONLY span tags with an id that matches our regex\n",
    "# use findAll to find all matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quote = span_tag.text\n",
    "quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### EXERCISE #####\n",
    "# Make a method  get_stock_price that takes in ANY stock ticker and grabs the current price\n",
    "# If the stock ticker doesn't exist, return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stock_price(ticker):\n",
    "    response = requests.get(\"http://google.com/finance?q=\"+ticker)\n",
    "    parser = BeautifulSoup(response.text, \"html.parser\")\n",
    "    pattern = re.compile(\"ref_\\d+_l\")\n",
    "    span_tag = parser.find(\"span\", attrs={\"id\":pattern})\n",
    "    if span_tag:\n",
    "        return span_tag.text\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ticker in ['ge', 'spy']:\n",
    "    print get_stock_price(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### UFO #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"http://www.nuforc.org/webreports/ndxe201608.html\")\n",
    "b = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the first sighting\n",
    "for tr in b.findAll('tr', attrs = {'valign':'TOP'})[:1]:\n",
    "    # the findChildren method returns all children underneath it\n",
    "    for child in tr.findChildren():\n",
    "        print child.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OK, it's a bit messy, Let's clean it up\n",
    "# Looks like the first element is the date, the 4th is the city, 6th if state, 8th is shape (this ones blank)\n",
    "# 13th is the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufo_sightings = {\n",
    "        'Date':[],\n",
    "        'City':[],\n",
    "        'State':[],\n",
    "        'Shape':[],\n",
    "        'Summary':[]\n",
    "    }\n",
    "\n",
    "for tr in b.findAll('tr', attrs = {'valign':'TOP'}):\n",
    "    # the findChildren method returns all children underneath it\n",
    "    ufo_sighting_info = []\n",
    "    for child in tr.findChildren():\n",
    "        ufo_sighting_info.append(child.text)\n",
    "    ufo_sightings['Date'].append(ufo_sighting_info[0])\n",
    "    ufo_sightings['City'].append(ufo_sighting_info[3])\n",
    "    ufo_sightings['State'].append(ufo_sighting_info[5])\n",
    "    ufo_sightings['Shape'].append(ufo_sighting_info[7])\n",
    "    ufo_sightings['Summary'].append(ufo_sighting_info[12])\n",
    "\n",
    "ufo_sightings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ufo_sightings) # MAGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SOME MORE EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NY TIMES ARTICLES ON HOME PAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://www.nytimes.com/\")\n",
    "parser = BeautifulSoup(response.text, \"html.parser\")\n",
    "for story in parser.findAll(\"h2\", attrs={'class':'story-heading'}):\n",
    "    print story.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# WIKIPEDIA FEATURED ARTICLE\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Wikipedia:Today%27s_featured_article\")\n",
    "parser = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser.find('div', attrs={'id':'mw-content-text'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
